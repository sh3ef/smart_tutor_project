# app.py - Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ (Ù…Ø¹ Ù…ÙŠØ²Ø© Chat History Memory ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù…)

import os
import sys
import streamlit as st
import traceback
import json
import tempfile
import re
import time
from datetime import datetime
from typing import Optional, Dict, Any, List
from pathlib import Path

# Ø¥ØµÙ„Ø§Ø­Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"

# Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© protobuf
import sys
try:
    import google.protobuf
    print(f"Protobuf version: {google.protobuf.__version__}")
except ImportError:
    print("Protobuf not installed")

# Ø¥ØµÙ„Ø§Ø­ distutils
try:
    import distutils
except ImportError:
    try:
        import setuptools
        sys.modules['distutils'] = setuptools
        print("âœ… Fixed distutils with setuptools")
    except ImportError:
        print("âš ï¸ Neither distutils nor setuptools available, continuing...")
        pass

try:
    import sqlite3
    sqlite_version = sqlite3.sqlite_version_info
    print(f"Current SQLite version: {sqlite3.sqlite_version}")
    
    if sqlite_version < (3, 35, 0):
        try:
            __import__('pysqlite3')
            sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
        except ImportError:
            print("âš ï¸ pysqlite3 not available, continuing with system SQLite")
    else:
        print("âœ… SQLite version is sufficient")
        
except Exception as e:
    print(f"Warning: SQLite fix failed: {e}")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ù…Ø®ØµØµØ© Ø¨Ø£Ù…Ø§Ù† (Ø¨ØµÙ…Øª)
try:
    from tutor_ai.gemini_client import GeminiClientVertexAI
    GEMINI_CLIENT_AVAILABLE = True
except Exception as e:
    GEMINI_CLIENT_AVAILABLE = False

try:
    from tutor_ai.prompt_engineering import UnifiedPromptEngine
    PROMPT_ENGINE_AVAILABLE = True
except Exception as e:
    PROMPT_ENGINE_AVAILABLE = False

try:
    from tutor_ai.knowledge_base_manager import KnowledgeBaseManager, check_rag_requirements
    KB_MANAGER_AVAILABLE = True
except Exception as e:
    KB_MANAGER_AVAILABLE = False
    def check_rag_requirements():
        return {"Status": False}

try:
    from tutor_ai.code_executor import save_svg_content_to_file
    CODE_EXECUTOR_AVAILABLE = True
except Exception as e:
    CODE_EXECUTOR_AVAILABLE = False
    def save_svg_content_to_file(svg_content: str, path: str) -> bool:
        try:
            with open(path, 'w', encoding='utf-8') as f:
                f.write(svg_content)
            return True
        except:
            return False

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ø§Ù…Ø©
APP_TITLE = "ğŸ¤– Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ"

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙÙˆÙ ÙˆØ§Ù„Ù…ÙˆØ§Ø¯
GRADE_SUBJECTS = {
    'grade_1': {
        'name': 'Ø§Ù„ØµÙ Ø§Ù„Ø£ÙˆÙ„ Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ',
        'subjects': {
            'arabic': 'Ù„ØºØªÙŠ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©',
            'math': 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª',
            'science': 'Ø§Ù„Ø¹Ù„ÙˆÙ…',
            'islamic': 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©',
            'english': 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'
        }
    },
    'grade_2': {
        'name': 'Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù†ÙŠ Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ',
        'subjects': {
            'arabic': 'Ù„ØºØªÙŠ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©',
            'math': 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª',
            'science': 'Ø§Ù„Ø¹Ù„ÙˆÙ…',
            'islamic': 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©',
            'english': 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'
        }
    },
    'grade_3': {
        'name': 'Ø§Ù„ØµÙ Ø§Ù„Ø«Ø§Ù„Ø« Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ',
        'subjects': {
            'arabic': 'Ù„ØºØªÙŠ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©',
            'math': 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª',
            'science': 'Ø§Ù„Ø¹Ù„ÙˆÙ…',
            'islamic': 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©',
            'english': 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'
        }
    },
    'grade_4': {
        'name': 'Ø§Ù„ØµÙ Ø§Ù„Ø±Ø§Ø¨Ø¹ Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ',
        'subjects': {
            'arabic': 'Ù„ØºØªÙŠ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©',
            'math': 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª',
            'science': 'Ø§Ù„Ø¹Ù„ÙˆÙ…',
            'islamic': 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©',
            'english': 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'
        }
    },
    'grade_5': {
        'name': 'Ø§Ù„ØµÙ Ø§Ù„Ø®Ø§Ù…Ø³ Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ',
        'subjects': {
            'arabic': 'Ù„ØºØªÙŠ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©',
            'math': 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª',
            'science': 'Ø§Ù„Ø¹Ù„ÙˆÙ…',
            'islamic': 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©',
            'english': 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'
        }
    },
    'grade_6': {
        'name': 'Ø§Ù„ØµÙ Ø§Ù„Ø³Ø§Ø¯Ø³ Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠ',
        'subjects': {
            'arabic': 'Ù„ØºØªÙŠ Ø§Ù„Ø¬Ù…ÙŠÙ„Ø©',
            'math': 'Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª',
            'science': 'Ø§Ù„Ø¹Ù„ÙˆÙ…',
            'islamic': 'Ø§Ù„ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ©',
            'english': 'Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©'
        }
    }
}

SUBJECT_FOLDERS = {
    'arabic': 'lughati',
    'math': 'Math',
    'science': 'Science',
    'islamic': 'Ø§Ù„Ø¯Ø±Ø§Ø³Ø§Øª Ø§Ù„Ø§Ø³Ù„Ø§Ù…ÙŠØ©',
    'english': 'English'
}

# === Ø¯ÙˆØ§Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© ===

class ChatHistoryAnalyzer:
    """Ù…Ø­Ù„Ù„ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹"""
    
    def __init__(self):
        # Ø§Ù„Ø¶Ù…Ø§Ø¦Ø± ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        self.reference_patterns = [
            r'\bÙ‡\b', r'\bÙ‡Ø§\b', r'\bÙ‡Ø°Ø§\b', r'\bÙ‡Ø°Ù‡\b', r'\bØ°Ù„Ùƒ\b', r'\bØªÙ„Ùƒ\b',
            r'\bØ§Ù„Ù…ÙˆØ¶ÙˆØ¹\b', r'\bØ§Ù„Ø¯Ø±Ø³\b', r'\bØ§Ù„Ø´Ø±Ø­\b', r'\bØ§Ù„Ù…Ø«Ø§Ù„\b',
            r'\bÙ†ÙØ³ Ø§Ù„Ø´ÙŠØ¡\b', r'\bÙ†ÙØ³ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹\b', r'\bÙ…Ø§ Ù‚Ù„ØªÙ‡\b', r'\bÙ…Ø§ Ø´Ø±Ø­ØªÙ‡\b',
            r'\bØ§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚\b', r'\bÙ…Ø§ Ø³Ø£Ù„Øª Ø¹Ù†Ù‡\b', r'\bØ§Ù„Ù„ÙŠ Ù‚Ù„ØªÙ‡\b'
        ]
        
        # ÙƒÙ„Ù…Ø§Øª Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø£Ùˆ Ø§Ù„ØªÙØµÙŠÙ„
        self.clarification_patterns = [
            r'Ø§Ø´Ø±Ø­.*Ø¨Ø§Ù„Ø±Ø³Ù…', r'Ø§Ø±Ø³Ù….*Ù„ÙŠ', r'ÙˆØ¶Ø­.*Ø¨Ø§Ù„Ø±Ø³Ù…', r'Ø¨Ø§Ù„ØµÙˆØ±', r'Ø¨Ø§Ù„Ø±Ø³Ù…',
            r'Ù…Ø¹ Ø±Ø³Ù…', r'Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ', r'ØµÙˆØ±Ø©', r'Ù…Ø«Ø§Ù„ Ø¨Ø§Ù„Ø±Ø³Ù…',
            r'ÙˆØ¶Ø­ Ø£ÙƒØ«Ø±', r'ÙØµÙ„ Ø£ÙƒØ«Ø±', r'Ø¨Ø§Ù„ØªÙØµÙŠÙ„', r'Ø£Ø±ÙŠØ¯ ØªÙØ§ØµÙŠÙ„',
            r'explain.*with.*drawing', r'draw.*for.*me', r'show.*picture'
        ]
        
        # ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø±ÙØ¶ Ø£Ùˆ Ø§Ù„ØªØµØ­ÙŠØ­
        self.correction_patterns = [
            r'\bÙ„Ø§\b', r'\bÙ„ÙŠØ³\b', r'\bØºÙŠØ± ØµØ­ÙŠØ­\b', r'\bØ®Ø·Ø£\b',
            r'Ù„Ø§ Ø£Ø±ÙŠØ¯', r'Ù„Ø§ Ø£ÙÙ‡Ù…', r'ØºÙŠØ± ÙˆØ§Ø¶Ø­', r'ØµØ¹Ø¨',
            r'\bno\b', r'\bnot\b', r'\bwrong\b'
        ]

    def has_references(self, question: str) -> bool:
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø³Ø§Ø¨Ù‚Ø©"""
        question_lower = question.lower().strip()
        return any(re.search(pattern, question_lower) for pattern in self.reference_patterns)
    
    def is_clarification_request(self, question: str) -> bool:
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ Ø£Ùˆ ØªÙØµÙŠÙ„"""
        question_lower = question.lower().strip()
        return any(re.search(pattern, question_lower) for pattern in self.clarification_patterns)
    
    def is_correction_request(self, question: str) -> bool:
        """ÙØ­Øµ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ØªØµØ­ÙŠØ­ Ø£Ùˆ Ø±ÙØ¶"""
        question_lower = question.lower().strip()
        return any(re.search(pattern, question_lower) for pattern in self.correction_patterns)
    
    def extract_last_topic(self, messages: List[Dict]) -> Optional[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø± Ù…ÙˆØ¶ÙˆØ¹ ØªÙ… Ù…Ù†Ø§Ù‚Ø´ØªÙ‡"""
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± Ø³Ø¤Ø§Ù„ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØ¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø¹Ù„Ù…
        user_messages = [msg for msg in messages if msg["role"] == "user"]
        assistant_messages = [msg for msg in messages if msg["role"] == "assistant"]
        
        if user_messages:
            last_user_question = user_messages[-1]["content"]
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„
            return self._extract_main_topic(last_user_question)
        
        return None
    
    def _extract_main_topic(self, question: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„"""
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
        topics_map = {
            'Ø§Ù„Ø¬Ù…Ø¹': ['Ø¬Ù…Ø¹', 'Ø²Ø§Ø¦Ø¯', '+', 'Ø¥Ø¶Ø§ÙØ©', 'addition'],
            'Ø§Ù„Ø·Ø±Ø­': ['Ø·Ø±Ø­', 'Ù†Ø§Ù‚Øµ', '-', 'subtraction'],
            'Ø§Ù„Ø¶Ø±Ø¨': ['Ø¶Ø±Ø¨', 'Ù…Ø¶Ø±ÙˆØ¨', 'Ã—', '*', 'multiplication'],
            'Ø§Ù„Ù‚Ø³Ù…Ø©': ['Ù‚Ø³Ù…Ø©', 'Ù…Ù‚Ø³ÙˆÙ…', 'Ã·', '/', 'division'],
            'Ø§Ù„Ø­Ø±ÙˆÙ': ['Ø­Ø±Ù', 'Ø­Ø±ÙˆÙ', 'Ø£Ø¨Ø¬Ø¯ÙŠØ©', 'letter', 'alphabet'],
            'Ø§Ù„Ø£Ø±Ù‚Ø§Ù…': ['Ø±Ù‚Ù…', 'Ø£Ø±Ù‚Ø§Ù…', 'Ø¹Ø¯', 'number', 'counting'],
            'Ø§Ù„Ù†Ø¨Ø§Øª': ['Ù†Ø¨Ø§Øª', 'Ù†Ø¨Ø§ØªØ§Øª', 'Ø´Ø¬Ø±Ø©', 'Ø²Ù‡Ø±Ø©', 'plant', 'tree'],
            'Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª': ['Ø­ÙŠÙˆØ§Ù†', 'Ø­ÙŠÙˆØ§Ù†Ø§Øª', 'Ù‚Ø·Ø©', 'ÙƒÙ„Ø¨', 'animal'],
            'Ø§Ù„Ø£Ø´ÙƒØ§Ù„': ['Ø´ÙƒÙ„', 'Ø£Ø´ÙƒØ§Ù„', 'Ù…Ø±Ø¨Ø¹', 'Ø¯Ø§Ø¦Ø±Ø©', 'Ù…Ø«Ù„Ø«', 'shape'],
            'Ø§Ù„Ø£Ù„ÙˆØ§Ù†': ['Ù„ÙˆÙ†', 'Ø£Ù„ÙˆØ§Ù†', 'Ø£Ø­Ù…Ø±', 'Ø£Ø²Ø±Ù‚', 'color']
        }
        
        question_lower = question.lower()
        for topic, keywords in topics_map.items():
            if any(keyword in question_lower for keyword in keywords):
                return topic
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø­Ø¯Ø¯ØŒ Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ ÙƒÙ„Ù…Ø© Ù…ÙÙŠØ¯Ø©
        words = question.split()
        meaningful_words = [word for word in words if len(word) > 2 and word not in ['ÙÙŠ', 'Ù…Ù†', 'Ø¥Ù„Ù‰', 'Ø¹Ù†', 'Ù…Ø¹', 'Ø¹Ù„Ù‰']]
        if meaningful_words:
            return meaningful_words[0]
        
        return "Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚"
    
    def build_context_summary(self, messages: List[Dict], max_context_length: int = 500) -> str:
        """Ø¨Ù†Ø§Ø¡ Ù…Ù„Ø®Øµ Ù„Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©"""
        if not messages:
            return ""
        
        # Ø£Ø®Ø° Ø¢Ø®Ø± 4 Ø±Ø³Ø§Ø¦Ù„ ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø¥Ø·Ø§Ù„Ø©
        recent_messages = messages[-4:] if len(messages) > 4 else messages
        
        context_parts = []
        for msg in recent_messages:
            if msg["role"] == "user":
                context_parts.append(f"Ø§Ù„Ø·Ø§Ù„Ø¨ Ø³Ø£Ù„: {msg['content']}")
            elif msg["role"] == "assistant" and 'explanation' in msg:
                # Ø£Ø®Ø° Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø´Ø±Ø­ ÙÙ‚Ø·
                explanation = msg['explanation'][:100] + "..." if len(msg['explanation']) > 100 else msg['explanation']
                context_parts.append(f"Ø§Ù„Ù…Ø¹Ù„Ù… Ø£Ø¬Ø§Ø¨: {explanation}")
        
        context_summary = "\n".join(context_parts)
        
        # Ù‚Ø·Ø¹ Ø§Ù„Ù†Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø·ÙˆÙŠÙ„Ø§Ù‹ Ø¬Ø¯Ø§Ù‹
        if len(context_summary) > max_context_length:
            context_summary = context_summary[:max_context_length] + "..."
        
        return context_summary

def classify_question_type(question: str, chat_history: List[Dict] = None) -> Dict[str, any]:
    """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ù…Ø­Ø³Ù†"""
    question_lower = question.lower().strip()
    analyzer = ChatHistoryAnalyzer()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø±Ø§Ø¬Ø¹ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    has_references = analyzer.has_references(question)
    is_clarification = analyzer.is_clarification_request(question)
    is_correction = analyzer.is_correction_request(question)
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ­ÙŠØ§Øª ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©
    greetings_patterns = [
        r'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…', r'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒ', r'Ù…Ø±Ø­Ø¨Ø§', r'Ù…Ø±Ø­Ø¨Ø§Ù‹', r'Ø£Ù‡Ù„Ø§', r'Ø£Ù‡Ù„Ø§Ù‹',
        r'ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±', r'Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±', r'ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ', r'ÙƒÙŠÙ Ø§Ù„Ø­Ø§Ù„',
        r'hello', r'hi', r'good morning', r'good evening', r'how are you'
    ]
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬
    curriculum_patterns = [
        r'Ø¹Ù„Ù…Ù†ÙŠ', r'Ø§Ø´Ø±Ø­.*Ù„ÙŠ', r'Ù…Ø§ Ù‡Ùˆ', r'Ù…Ø§ Ù‡ÙŠ', r'ÙƒÙŠÙ.*Ø£(Ø¬Ù…Ø¹|Ø·Ø±Ø­|Ø¶Ø±Ø¨|Ù‚Ø³Ù…)',
        r'Ù…Ø§.*Ù…Ø¹Ù†Ù‰', r'Ø£Ø±ÙŠØ¯.*Ø£ØªØ¹Ù„Ù…', r'Ø­Ø±Ù.*Ø§Ù„[Ø£-ÙŠ]', r'Ø±Ù‚Ù….*\d+', r'Ø¹Ù…Ù„ÙŠØ©.*',
        r'Ø¯Ø±Ø³.*', r'ÙˆØ­Ø¯Ø©.*', r'teach me', r'explain.*', r'what is', r'how to', r'show me'
    ]
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙŠ ØªØ­ØªØ§Ø¬ Ø±Ø³Ù… Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­
    explicit_drawing_patterns = [
        r'Ø§Ø±Ø³Ù….*Ù„ÙŠ', r'Ø±Ø³Ù….*', r'Ø£Ø±ÙŠØ¯.*Ø±Ø³Ù…', r'ÙˆØ¶Ø­.*Ø¨Ø§Ù„Ø±Ø³Ù…', r'Ø¨Ø§Ù„Ø±Ø³Ù…',
        r'Ø§Ø´Ø±Ø­.*Ø¨Ø§Ù„ØµÙˆØ±', r'Ù…Ø¹.*Ø±Ø³Ù…', r'draw.*', r'show.*drawing', r'with.*picture'
    ]
    
    # Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ©
    math_patterns = [
        r'\d+\s*[+\-Ã—Ã·]\s*\d+', r'Ø¬Ù…Ø¹.*\d+', r'Ø·Ø±Ø­.*\d+', r'Ø¶Ø±Ø¨.*\d+',
        r'Ù‚Ø³Ù…Ø©.*\d+', r'Ù…Ø¹Ø§Ø¯Ù„Ø©', r'Ø­Ø³Ø§Ø¨', r'Ø¹Ù…Ù„ÙŠØ©.*Ø­Ø³Ø§Ø¨ÙŠØ©'
    ]
    
    # Ù…ÙˆØ§Ø¶ÙŠØ¹ ØªØ­ØªØ§Ø¬ Ø±Ø³Ù… Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ (Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ Ù…Ø­Ø³Ù†)
    high_priority_visual_topics = [
        # Ø±ÙŠØ§Ø¶ÙŠØ§Øª - Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ©
        r'Ø¬Ù…Ø¹', r'Ø·Ø±Ø­', r'Ø¶Ø±Ø¨', r'Ù‚Ø³Ù…Ø©', r'Ø¹Ù…Ù„ÙŠØ©.*Ø­Ø³Ø§Ø¨ÙŠØ©',
        r'Ù…Ø±Ø¨Ø¹', r'Ù…Ø«Ù„Ø«', r'Ø¯Ø§Ø¦Ø±Ø©', r'Ù…Ø³ØªØ·ÙŠÙ„', r'Ø´ÙƒÙ„', r'Ø£Ø´ÙƒØ§Ù„', r'Ù‡Ù†Ø¯Ø³Ø©',
        r'ÙƒØ³Ø±', r'ÙƒØ³ÙˆØ±', r'Ù†ØµÙ', r'Ø±Ø¨Ø¹', r'Ø«Ù„Ø«',
        r'Ø£Ø±Ù‚Ø§Ù…', r'Ø£Ø¹Ø¯Ø§Ø¯', r'Ø¹Ø¯', r'ØªØ±Ù‚ÙŠÙ…',
        # Ø¹Ù„ÙˆÙ… - Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ©  
        r'Ù†Ø¨Ø§Øª', r'Ù†Ø¨Ø§ØªØ§Øª', r'Ø´Ø¬Ø±Ø©', r'Ø²Ù‡Ø±Ø©', r'ÙˆØ±Ù‚Ø©', r'Ø¬Ø°Ø±', r'Ø³Ø§Ù‚',
        r'Ø­ÙŠÙˆØ§Ù†', r'Ø­ÙŠÙˆØ§Ù†Ø§Øª', r'Ù‚Ø·Ø©', r'ÙƒÙ„Ø¨', r'ÙÙŠÙ„', r'Ø£Ø³Ø¯', r'Ø·Ø§Ø¦Ø±', r'Ø³Ù…Ùƒ',
        r'Ø¬Ø³Ù….*Ø§Ù„Ø¥Ù†Ø³Ø§Ù†', r'Ø¹ÙŠÙ†', r'Ø£Ø°Ù†', r'ÙŠØ¯', r'Ù‚Ø¯Ù…', r'Ø±Ø£Ø³',
        r'Ø¯ÙˆØ±Ø©.*Ø­ÙŠØ§Ø©', r'Ù†Ù…Ùˆ', r'ØªÙƒØ§Ø«Ø±',
        # Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© - Ø­Ø±ÙˆÙ ÙÙ‚Ø·
        r'Ø­Ø±Ù', r'Ø­Ø±ÙˆÙ', r'Ø£Ø¨Ø¬Ø¯ÙŠØ©',
        r'Ø®Ø·', r'ÙƒØªØ§Ø¨Ø©.*Ø­Ø±Ù'
    ]
    
    medium_priority_visual_topics = [
        # Ø¹Ù„ÙˆÙ… Ø£Ø®Ø±Ù‰
        r'Ø·Ù‚Ø³', r'Ù…Ø·Ø±', r'Ø´Ù…Ø³', r'Ø³Ø­Ø§Ø¨', r'Ø«Ù„Ø¬', r'Ø±ÙŠØ§Ø­',
        r'Ù…Ø¬Ù…ÙˆØ¹Ø©.*Ø´Ù…Ø³ÙŠØ©', r'ÙƒÙˆØ§ÙƒØ¨', r'Ù‚Ù…Ø±', r'Ù†Ø¬ÙˆÙ…',
        r'Ù…Ø§Ø¡', r'Ù‡ÙˆØ§Ø¡', r'ØªØ±Ø¨Ø©',
        # Ø£Ù„ÙˆØ§Ù† ÙˆØ£Ø´ÙŠØ§Ø¡ Ø¨ØµØ±ÙŠØ©
        r'Ù„ÙˆÙ†', r'Ø£Ù„ÙˆØ§Ù†', r'Ø£Ø­Ù…Ø±', r'Ø£Ø²Ø±Ù‚', r'Ø£Ø®Ø¶Ø±', r'Ø£ØµÙØ±', r'Ø£Ø³ÙˆØ¯', r'Ø£Ø¨ÙŠØ¶',
        r'ÙƒØ¨ÙŠØ±', r'ØµØºÙŠØ±', r'Ø·ÙˆÙŠÙ„', r'Ù‚ØµÙŠØ±', r'Ø³Ù…ÙŠÙƒ', r'Ø±ÙÙŠØ¹'
    ]
    
    # Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø±Ø³Ù… Ø¹Ø§Ø¯Ø© (Ù†ØµÙˆØµØŒ Ù‚ÙˆØ§Ø¹Ø¯ØŒ ØªØ¹Ø±ÙŠÙØ§Øª Ù…Ø¬Ø±Ø¯Ø©)
    text_only_topics = [
        r'Ù‚Ø§Ø¹Ø¯Ø©', r'Ù‚Ø§Ù†ÙˆÙ†', r'ØªØ¹Ø±ÙŠÙ', r'Ù…Ø¹Ù†Ù‰', r'Ù…ÙÙ‡ÙˆÙ…',
        r'ØªØ§Ø±ÙŠØ®', r'Ù‚ØµØ©', r'Ø­ÙƒØ§ÙŠØ©', r'Ø³ÙŠØ±Ø©',
        r'Ø¯Ø¹Ø§Ø¡', r'Ø¢ÙŠØ©', r'Ø­Ø¯ÙŠØ«', r'Ø°ÙƒØ±',
        r'Ø¥Ù…Ù„Ø§Ø¡', r'Ù†Ø­Ùˆ', r'ØµØ±Ù', r'Ø¨Ù„Ø§ØºØ©',
        r'ÙƒÙ„Ù…Ø©', r'ÙƒÙ„Ù…Ø§Øª', r'Ø¬Ù…Ù„Ø©', r'Ø¬Ù…Ù„'  # Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø­Ø±ÙˆÙ
    ]
    
    is_greeting = any(re.search(pattern, question_lower) for pattern in greetings_patterns)
    needs_curriculum_search = any(re.search(pattern, question_lower) for pattern in curriculum_patterns)
    explicit_drawing_requested = any(re.search(pattern, question_lower) for pattern in explicit_drawing_patterns)
    is_math_question = any(re.search(pattern, question_lower) for pattern in math_patterns)
    
    # ÙØ­Øµ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¨Ø£ÙˆÙ„ÙˆÙŠØ§Øª
    is_high_priority_visual = any(re.search(pattern, question_lower) for pattern in high_priority_visual_topics)
    is_medium_priority_visual = any(re.search(pattern, question_lower) for pattern in medium_priority_visual_topics)
    is_text_only_topic = any(re.search(pattern, question_lower) for pattern in text_only_topics)
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ØªØ¹Ù„ÙŠÙ…ÙŠ
    is_educational = needs_curriculum_search or is_math_question or len(question.split()) > 3
    
    # Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ø±Ø³Ù…
    smart_drawing_decision = False
    drawing_confidence = 0  # Ù…Ù† 0 Ø¥Ù„Ù‰ 100
    
    if explicit_drawing_requested:
        # Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø§Ù„Ø±Ø³Ù… ØµØ±Ø§Ø­Ø© - Ø£ÙˆÙ„ÙˆÙŠØ© Ù‚ØµÙˆÙ‰
        smart_drawing_decision = True
        drawing_confidence = 100
    elif is_text_only_topic and not is_high_priority_visual:
        # Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù†ØµÙŠØ© Ù„Ø§ ØªØ­ØªØ§Ø¬ Ø±Ø³Ù… Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        smart_drawing_decision = False
        drawing_confidence = 10
    elif is_high_priority_visual:
        # Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ØªØ­ØªØ§Ø¬ Ø±Ø³Ù… Ø¯Ø§Ø¦Ù…Ø§Ù‹
        smart_drawing_decision = True
        drawing_confidence = 90
    elif is_math_question:
        # Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© ØªØ­ØªØ§Ø¬ Ø±Ø³Ù… Ø¹Ø§Ø¯Ø©
        smart_drawing_decision = True
        drawing_confidence = 85
    elif is_medium_priority_visual:
        # Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…ØªÙˆØ³Ø·Ø© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
        smart_drawing_decision = True
        drawing_confidence = 70
    elif has_references and is_clarification:
        # Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚
        smart_drawing_decision = True
        drawing_confidence = 80
    elif is_educational and any(word in question_lower for word in ['ÙƒÙŠÙ', 'Ø£ÙŠÙ†', 'Ù…ØªÙ‰', 'Ù„Ù…Ø§Ø°Ø§', 'how', 'where', 'when', 'why']):
        # Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªÙØ³ÙŠØ±ÙŠØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©
        smart_drawing_decision = True
        drawing_confidence = 60
    elif is_educational and not is_greeting:
        # Ø£Ø³Ø¦Ù„Ø© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø¹Ø§Ù…Ø©
        smart_drawing_decision = True
        drawing_confidence = 50
    
    # Ù‚Ø±Ø§Ø± Ù†Ù‡Ø§Ø¦ÙŠ: Ø±Ø³Ù… ÙÙ‚Ø· Ù„Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© ÙˆÙ„ÙŠØ³ Ø§Ù„ØªØ­ÙŠØ§Øª
    needs_drawing = smart_drawing_decision and not is_greeting and drawing_confidence >= 50
    
    return {
        'is_greeting': is_greeting,
        'is_educational': is_educational,
        'needs_curriculum_search': is_educational and not is_greeting,
        'needs_drawing': needs_drawing,
        'drawing_confidence': drawing_confidence,
        'is_math_question': is_math_question,
        'is_high_priority_visual': is_high_priority_visual,
        'is_medium_priority_visual': is_medium_priority_visual,
        'is_text_only_topic': is_text_only_topic,
        'explicit_drawing_requested': explicit_drawing_requested,
        'question_complexity': len(question.split()),
        'has_references': has_references,
        'is_clarification': is_clarification,
        'is_correction': is_correction,
        'needs_context': has_references or is_clarification or is_correction,
        'smart_decision_reason': _get_drawing_decision_reason(
            needs_drawing, is_high_priority_visual, is_medium_priority_visual, 
            is_math_question, explicit_drawing_requested, is_text_only_topic, 
            has_references, is_clarification, drawing_confidence
        )
    }

def _get_drawing_decision_reason(needs_drawing: bool, is_high_visual: bool, is_medium_visual: bool,
                               is_math: bool, explicit: bool, is_text_only: bool, 
                               has_refs: bool, is_clarif: bool, confidence: int) -> str:
    """Ø´Ø±Ø­ Ø³Ø¨Ø¨ Ù‚Ø±Ø§Ø± Ø§Ù„Ø±Ø³Ù… Ù„Ù„ØªØ´Ø®ÙŠØµ"""
    if explicit:
        return f"Ø·Ù„Ø¨ Ø±Ø³Ù… ØµØ±ÙŠØ­ (Ø«Ù‚Ø©: {confidence}%)"
    elif is_text_only and not is_high_visual:
        return f"Ù…ÙˆØ¶ÙˆØ¹ Ù†ØµÙŠ Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Ø±Ø³Ù… (Ø«Ù‚Ø©: {confidence}%)"
    elif is_high_visual:
        return f"Ù…ÙˆØ¶ÙˆØ¹ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙŠØ­ØªØ§Ø¬ Ø±Ø³Ù… (Ø«Ù‚Ø©: {confidence}%)"
    elif is_math:
        return f"Ù…ÙˆØ¶ÙˆØ¹ Ø±ÙŠØ§Ø¶ÙŠ ÙŠØ­ØªØ§Ø¬ Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ (Ø«Ù‚Ø©: {confidence}%)"
    elif is_medium_visual:
        return f"Ù…ÙˆØ¶ÙˆØ¹ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† Ø§Ù„Ø±Ø³Ù… (Ø«Ù‚Ø©: {confidence}%)"
    elif has_refs and is_clarif:
        return f"Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚ (Ø«Ù‚Ø©: {confidence}%)"
    elif needs_drawing:
        return f"Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ: Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† Ø§Ù„Ø±Ø³Ù… (Ø«Ù‚Ø©: {confidence}%)"
    else:
        return f"Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Ø±Ø³Ù… (Ø«Ù‚Ø©: {confidence}%)"

def get_greeting_response(question: str, grade_key: str, subject_key: str) -> Dict[str, any]:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„ØªØ­ÙŠØ§Øª ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©"""
    question_lower = question.lower().strip()
    
    grade_name = GRADE_SUBJECTS[grade_key]['name']
    subject_name = GRADE_SUBJECTS[grade_key]['subjects'][subject_key]
    
    # Ø±Ø¯ÙˆØ¯ Ù…Ø®ØªÙ„ÙØ© Ù„Ù„ØªØ­ÙŠØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    if 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…' in question_lower or 'Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒ' in question_lower:
        explanation = f"ÙˆØ¹Ù„ÙŠÙƒÙ… Ø§Ù„Ø³Ù„Ø§Ù… ÙˆØ±Ø­Ù…Ø© Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø±ÙƒØ§ØªÙ‡ ÙŠØ§ Ø¨Ø·Ù„! ğŸŒŸ Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! Ø£Ù†Ø§ Ù…Ø¹Ù„Ù…Ùƒ Ø§Ù„Ø°ÙƒÙŠØŒ Ù…Ø³ØªØ¹Ø¯ Ù„Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ ØªØ¹Ù„Ù… {subject_name} Ù„Ù„ØµÙ {grade_name}. Ù…Ø§ Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯ Ø£Ù† Ù†ØªØ¹Ù„Ù…Ù‡ Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸ“šâœ¨"
    elif any(word in question_lower for word in ['Ù…Ø±Ø­Ø¨Ø§', 'Ù…Ø±Ø­Ø¨Ø§Ù‹', 'Ø£Ù‡Ù„Ø§', 'Ø£Ù‡Ù„Ø§Ù‹', 'hello', 'hi']):
        explanation = f"Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ ÙŠØ§ ØµØºÙŠØ±ÙŠ! ğŸ‰ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ø¯Ø±Ø³ {subject_name}! Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ø£Ø¬Ø¹Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù…ØªØ¹Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹ Ù„Ùƒ. Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡ ØªØ±ÙŠØ¯ ØªØ¹Ù„Ù…Ù‡! ğŸ¤“ğŸ’«"
    elif any(word in question_lower for word in ['ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±', 'good morning']):
        explanation = f"ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± ÙŠØ§ Ù†Ø¬Ù…! â˜€ï¸ Ø£ØªÙ…Ù†Ù‰ Ù„Ùƒ ÙŠÙˆÙ…Ø§Ù‹ Ø±Ø§Ø¦Ø¹Ø§Ù‹ Ù…Ù„ÙŠØ¦Ø§Ù‹ Ø¨Ø§Ù„ØªØ¹Ù„Ù… ÙˆØ§Ù„Ù…Ø±Ø­! Ù…Ø³ØªØ¹Ø¯ Ù„Ù†Ø¨Ø¯Ø£ Ø¯Ø±Ø³ {subject_name} Ø§Ù„ÙŠÙˆÙ…ØŸ ğŸŒ…ğŸ“–"
    elif any(word in question_lower for word in ['Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±', 'good evening']):
        explanation = f"Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ± ÙŠØ§ Ø¨Ø·Ù„! ğŸŒ™ Ø£Ø±Ø¬Ùˆ Ø£Ù† ÙŠÙƒÙˆÙ† ÙŠÙˆÙ…Ùƒ ÙƒØ§Ù† Ø¬Ù…ÙŠÙ„Ø§Ù‹! Ù‡ÙŠØ§ Ù†Ø®ØªØªÙ… Ø§Ù„ÙŠÙˆÙ… Ø¨ØªØ¹Ù„Ù… Ø´ÙŠØ¡ Ø¬Ø¯ÙŠØ¯ ÙÙŠ {subject_name}! â­ğŸ“š"
    elif any(word in question_lower for word in ['ÙƒÙŠÙ Ø­Ø§Ù„Ùƒ', 'ÙƒÙŠÙ Ø§Ù„Ø­Ø§Ù„', 'how are you']):
        explanation = f"Ø£Ù†Ø§ Ø¨Ø®ÙŠØ± ÙˆØ§Ù„Ø­Ù…Ø¯ Ù„Ù„Ù‡ØŒ Ø´ÙƒØ±Ø§Ù‹ Ù„Ø³Ø¤Ø§Ù„Ùƒ! ğŸ˜Š Ø£Ø´Ø¹Ø± Ø¨Ø§Ù„Ø­Ù…Ø§Ø³ Ù„Ø£Ù†Ù†ÙŠ Ø³Ø£Ø³Ø§Ø¹Ø¯Ùƒ ÙÙŠ ØªØ¹Ù„Ù… {subject_name}! ÙˆØ£Ù†ØªØŒ ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ Ù…Ø³ØªØ¹Ø¯ Ù„Ù„ØªØ¹Ù„Ù…ØŸ ğŸˆğŸ“"
    else:
        explanation = f"Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ ÙŠØ§ ØµØ¯ÙŠÙ‚ÙŠ! ğŸ‘‹ Ø£Ù†Ø§ Ù…Ø¹Ù„Ù…Ùƒ Ø§Ù„Ø°ÙƒÙŠ ÙˆÙ…Ø³ØªØ¹Ø¯ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ {subject_name} Ù„Ù„ØµÙ {grade_name}. Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡ ØªØ±ÙŠØ¯ ØªØ¹Ù„Ù…Ù‡! ğŸš€ğŸ“š"
    
    return {
        'explanation': explanation,
        'svg_code': None,  # Ù„Ø§ Ø±Ø³Ù… Ù„Ù„ØªØ­ÙŠØ§Øª
        'quality_scores': {'explanation': 100, 'svg': 100},
        'quality_issues': [],
        'search_status': 'greeting'
    }

def should_search_curriculum(question: str, question_type: Dict[str, any]) -> bool:
    """ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø£Ù… Ù„Ø§"""
    # Ù„Ø§ ØªØ¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬ Ù„Ù„ØªØ­ÙŠØ§Øª
    if question_type['is_greeting']:
        return False
    
    # Ù„Ø§ ØªØ¨Ø­Ø« Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (ÙƒÙ„Ù…Ø© Ø£Ùˆ ÙƒÙ„Ù…ØªÙŠÙ†) Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹
    if question_type['question_complexity'] <= 2 and not question_type['is_educational'] and not question_type['has_references']:
        return False
    
    # Ø§Ø¨Ø­Ø« Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø£Ùˆ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹
    return question_type['needs_curriculum_search'] or question_type['has_references']

def create_smart_prompt(question: str, question_type: Dict[str, any], app_subject_key: str, 
                       grade_key: str, retrieved_context_str: Optional[str], prompt_engine, 
                       chat_history: List[Dict] = None) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø±ÙˆÙ…Ø¨Øª Ø°ÙƒÙŠ ÙŠØ±Ø§Ø¹ÙŠ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù…"""
    
    # Ø¨Ù†Ø§Ø¡ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ù…Ø±Ø§Ø¬Ø¹
    conversation_context = ""
    if question_type['needs_context'] and chat_history:
        analyzer = ChatHistoryAnalyzer()
        context_summary = analyzer.build_context_summary(chat_history)
        last_topic = analyzer.extract_last_topic(chat_history)
        
        if context_summary:
            conversation_context = f"""
**Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:**
{context_summary}

**Ø¢Ø®Ø± Ù…ÙˆØ¶ÙˆØ¹ ØªÙ… Ù…Ù†Ø§Ù‚Ø´ØªÙ‡:** {last_topic if last_topic else 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'}

**Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø©:** Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ "{question}" ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ù‡ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø³Ø§Ø¨Ù‚. 
ÙŠØ±Ø¬Ù‰ ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø§ ØªÙ… Ù…Ù†Ø§Ù‚Ø´ØªÙ‡ Ù…Ø³Ø¨Ù‚Ø§Ù‹.
"""
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    base_prompt = prompt_engine.get_specialized_prompt(
        question=question,
        app_subject_key=app_subject_key,
        grade_key=grade_key,
        retrieved_context_str=retrieved_context_str,
        conversation_context=conversation_context
    )
    
    # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø®Ø§ØµØ© Ø¨Ù‚Ø±Ø§Ø± Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø­Ø³Ù†
    if question_type['needs_drawing']:
        smart_drawing_instruction = f"""
**ØªØ¹Ù„ÙŠÙ…Ø© Ø°ÙƒÙŠØ© Ù„Ù„Ø±Ø³Ù… (Ø«Ù‚Ø© {question_type['drawing_confidence']}%):**
ØªÙ… Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ Ø¨Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªØ§Ø¬ Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ.
Ø§Ù„Ø³Ø¨Ø¨: {question_type.get('smart_decision_reason', 'Ù…ÙˆØ¶ÙˆØ¹ ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø§Ù„Ø¨ØµØ±ÙŠ')}

ÙŠØ±Ø¬Ù‰ Ø¥Ù†ØªØ§Ø¬ Ø±Ø³Ù… SVG Ù…Ù†Ø§Ø³Ø¨ ÙˆÙˆØ§Ø¶Ø­ ÙŠØ³Ø§Ø¹Ø¯ ÙÙŠ ÙÙ‡Ù… Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø¨Ø´ÙƒÙ„ Ø¨ØµØ±ÙŠ.
Ø§Ø¬Ø¹Ù„ Ø§Ù„Ø±Ø³Ù… Ø¨Ø³ÙŠØ· ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ø¹Ù…Ø± Ø§Ù„Ø·ÙÙ„ ÙˆÙ…Ù„ÙˆÙ† ÙˆØ¬Ø°Ø§Ø¨.
**ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø±Ø³Ù… ÙŠØ³Ø§Ù‡Ù… ÙØ¹Ù„Ø§Ù‹ ÙÙŠ Ø§Ù„ÙÙ‡Ù… ÙˆÙ„ÙŠØ³ Ù…Ø¬Ø±Ø¯ Ø²Ø®Ø±ÙØ©.**
"""
        base_prompt += "\n" + smart_drawing_instruction
    else:
        no_drawing_instruction = f"""
**ØªØ¹Ù„ÙŠÙ…Ø© Ø¹Ø¯Ù… Ø§Ù„Ø±Ø³Ù… (Ø«Ù‚Ø© {question_type['drawing_confidence']}%):**
ØªÙ… Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ Ø¨Ø£Ù† Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù„Ø§ ÙŠØ­ØªØ§Ø¬ Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ.
Ø§Ù„Ø³Ø¨Ø¨: {question_type.get('smart_decision_reason', 'Ù…ÙˆØ¶ÙˆØ¹ Ù„Ø§ ÙŠØ³ØªÙÙŠØ¯ Ù…Ù† Ø§Ù„Ø±Ø³Ù…')}

ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† `svg_code` Ù‡Ùˆ `null` ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©.
Ø±ÙƒØ² Ø¹Ù„Ù‰ ØªÙ‚Ø¯ÙŠÙ… Ø´Ø±Ø­ Ù†ØµÙŠ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙŠØ¯ ÙÙ‚Ø·.
"""
        base_prompt += "\n" + no_drawing_instruction
    
    if question_type['is_greeting']:
        greeting_instruction = """
**ØªØ¹Ù„ÙŠÙ…Ø© Ø®Ø§ØµØ© Ù„Ù„ØªØ­ÙŠØ§Øª:**
Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ ØªØ­ÙŠØ© Ø£Ùˆ Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ. Ù„Ø§ ØªØ¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬ ÙˆÙ„Ø§ ØªØ±Ø³Ù… Ø£ÙŠ Ø´ÙŠØ¡.
Ù‚Ø¯Ù… Ø±Ø¯Ø§Ù‹ ÙˆØ¯ÙˆØ¯Ø§Ù‹ ÙˆÙ…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ù„Ø·ÙÙ„ ÙÙŠ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø§Ø¨ØªØ¯Ø§Ø¦ÙŠØ©.
"""
        base_prompt += "\n" + greeting_instruction
    
    if question_type['has_references']:
        reference_instruction = """
**ØªØ¹Ù„ÙŠÙ…Ø© Ø®Ø§ØµØ© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹:**
Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø³Ø§Ø¨Ù‚Ø©. ØªØ£ÙƒØ¯ Ù…Ù† ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„ÙŠÙ‡.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„ØªÙ‚Ø¯ÙŠÙ… Ø¥Ø¬Ø§Ø¨Ø© Ù…ØªØ±Ø§Ø¨Ø·Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©.
"""
        base_prompt += "\n" + reference_instruction
    
    return base_prompt

# === Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ===

def load_environment_variables_silently():
    """ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Streamlit Secrets Ø¨ØµÙ…Øª"""
    try:
        if hasattr(st, 'secrets'):
            project_id = st.secrets.get("GCP_PROJECT_ID")
            location = st.secrets.get("GCP_LOCATION", "us-central1") 
            credentials_json = st.secrets.get("GOOGLE_APPLICATION_CREDENTIALS_JSON")
            
            if project_id and credentials_json:
                try:
                    if isinstance(credentials_json, str):
                        credentials_dict = json.loads(credentials_json)
                    else:
                        credentials_dict = credentials_json
                        
                    required_keys = ['type', 'project_id', 'private_key', 'client_email']
                    missing_keys = [key for key in required_keys if key not in credentials_dict]
                    
                    if not missing_keys:
                        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as f:
                            json.dump(credentials_dict, f)
                            credentials_path = f.name
                        
                        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path
                        return project_id, location, credentials_path
                        
                except json.JSONDecodeError:
                    return None, None, None
                except Exception:
                    return None, None, None
            
        return None, None, None
                    
    except Exception:
        return None, None, None

def check_knowledge_base_detailed_status(project_id: str, location: str) -> Dict[str, Any]:
    """ÙØ­Øµ Ù…ÙØµÙ„ Ù„Ø­Ø§Ù„Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø¹ ØªØ´Ø®ÙŠØµ Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ù…Ø´Ø§ÙƒÙ„"""
    if not KB_MANAGER_AVAILABLE:
        return {
            "available": False,
            "reason": "KnowledgeBaseManager ØºÙŠØ± Ù…ØªØ§Ø­",
            "details": "Ù…ÙƒØªØ¨Ø§Øª RAG ØºÙŠØ± Ù…Ø«Ø¨ØªØ© Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­",
            "docs_exist": False,
            "dbs_exist": False,
            "total_expected": 0,
            "total_found_docs": 0,
            "total_found_dbs": 0,
            "missing_docs": [],
            "missing_dbs": [],
            "empty_docs": [],
            "build_errors": [],
            "grade_details": {}
        }
    
    try:
        knowledge_docs_path = Path("knowledge_base_docs")
        docs_exist = knowledge_docs_path.exists()
        
        chroma_dbs_path = Path("chroma_dbs")
        dbs_exist = chroma_dbs_path.exists()
        
        detailed_status = {
            "available": True,
            "docs_exist": docs_exist,
            "dbs_exist": dbs_exist,
            "grade_details": {},
            "total_expected": 0,
            "total_found_docs": 0,
            "total_found_dbs": 0,
            "missing_docs": [],
            "missing_dbs": [],
            "empty_docs": [],
            "build_errors": []
        }
        
        # ÙØ­Øµ ØªÙØµÙŠÙ„ÙŠ Ù„ÙƒÙ„ ØµÙ ÙˆÙ…Ø§Ø¯Ø©
        for grade_key, grade_info in GRADE_SUBJECTS.items():
            grade_details = {"name": grade_info['name'], "subjects": {}}
            
            for subject_key, subject_name in grade_info['subjects'].items():
                subject_folder = SUBJECT_FOLDERS.get(subject_key, subject_key)
                detailed_status["total_expected"] += 1
                
                # ÙØ­Øµ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª
                docs_path = knowledge_docs_path / grade_key / subject_folder
                docs_status = {
                    "path": str(docs_path),
                    "exists": docs_path.exists(),
                    "has_files": False,
                    "file_count": 0,
                    "file_types": []
                }
                
                if docs_path.exists():
                    try:
                        files = list(docs_path.glob("*"))
                        docs_status["file_count"] = len([f for f in files if f.is_file()])
                        docs_status["has_files"] = docs_status["file_count"] > 0
                        docs_status["file_types"] = list(set([f.suffix for f in files if f.is_file()]))
                        
                        if docs_status["has_files"]:
                            detailed_status["total_found_docs"] += 1
                        else:
                            detailed_status["empty_docs"].append(f"{grade_key}/{subject_folder}")
                    except Exception as e:
                        docs_status["error"] = str(e)
                        detailed_status["build_errors"].append(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {docs_path}: {e}")
                else:
                    detailed_status["missing_docs"].append(f"{grade_key}/{subject_folder}")
                
                # ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                collection_name = f"{grade_key}_{subject_folder.replace(' ', '_').lower()}_coll"
                db_path = chroma_dbs_path / collection_name
                db_status = {
                    "collection_name": collection_name,
                    "path": str(db_path),
                    "exists": db_path.exists(),
                    "has_data": False
                }
                
                if db_path.exists():
                    try:
                        data_files = list(db_path.glob("**/*"))
                        db_status["has_data"] = len([f for f in data_files if f.is_file()]) > 0
                        
                        if db_status["has_data"]:
                            detailed_status["total_found_dbs"] += 1
                        else:
                            detailed_status["missing_dbs"].append(collection_name)
                    except Exception as e:
                        db_status["error"] = str(e)
                        detailed_status["build_errors"].append(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© {db_path}: {e}")
                else:
                    detailed_status["missing_dbs"].append(collection_name)
                
                grade_details["subjects"][subject_key] = {
                    "name": subject_name,
                    "folder": subject_folder,
                    "docs": docs_status,
                    "db": db_status
                }
            
            detailed_status["grade_details"][grade_key] = grade_details
        
        return detailed_status
        
    except Exception as e:
        # ÙÙŠ Ø­Ø§Ù„Ø© Ø­Ø¯ÙˆØ« Ø®Ø·Ø£ØŒ Ø¥Ø±Ø¬Ø§Ø¹ Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¢Ù…Ù†Ø©
        return {
            "available": False,
            "reason": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙØ­Øµ: {str(e)}",
            "details": str(e),
            "docs_exist": False,
            "dbs_exist": False,
            "total_expected": 0,
            "total_found_docs": 0,
            "total_found_dbs": 0,
            "missing_docs": [],
            "missing_dbs": [],
            "empty_docs": [],
            "build_errors": [str(e)],
            "grade_details": {}
        }

@st.cache_data
def build_knowledge_bases_with_error_handling(project_id: str, location: str, force_rebuild: bool = False) -> Dict[str, Any]:
    """Ø¨Ù†Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© ØªÙØµÙŠÙ„ÙŠØ© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡ (Ø¨ØµÙ…Øª)"""
    status = check_knowledge_base_detailed_status(project_id, location)
    
    if not status["available"]:
        return {"success": False, "message": "Ù…Ø¯ÙŠØ± Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© ØºÙŠØ± Ù…ØªØ§Ø­", "details": status.get("details", "")}
    
    if not status["docs_exist"] or status["total_found_docs"] == 0:
        return {
            "success": False,
            "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„ÙØ§Øª Ù…Ù†Ù‡Ø¬ Ø¯Ø±Ø§Ø³ÙŠ Ù„Ø¨Ù†Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ù†Ù‡Ø§",
            "suggestion": "ØªØ£ÙƒØ¯ Ù…Ù† Ø±ÙØ¹ Ù…Ø¬Ù„Ø¯ knowledge_base_docs Ù…Ø¹ Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù†Ù‡Ø¬",
            "missing_docs": status["missing_docs"],
            "empty_docs": status["empty_docs"]
        }
    
    if not force_rebuild and status["total_found_dbs"] > 0 and len(status["missing_dbs"]) == 0:
        return {
            "success": True, 
            "message": "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆÙ„Ø§ ØªØ­ØªØ§Ø¬ Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡",
            "found_dbs": status["total_found_dbs"]
        }
    
    results = {
        "success": True,
        "built_databases": [],
        "failed_databases": [],
        "skipped_databases": [],
        "detailed_errors": []
    }
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªÙŠ Ø¨Ù‡Ø§ Ù…Ù„ÙØ§Øª
    subjects_to_build = [
        (grade_key, subject_key, subject_folder)
        for grade_key, grade_info in GRADE_SUBJECTS.items()
        for subject_key, subject_folder in [(sk, SUBJECT_FOLDERS.get(sk, sk)) for sk in grade_info['subjects'].keys()]
        if status["grade_details"][grade_key]["subjects"][subject_key]["docs"]["has_files"]
    ]
    
    total_subjects = len(subjects_to_build)
    
    if total_subjects == 0:
        return {
            "success": False,
            "message": "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª ØµØ§Ù„Ø­Ø© Ù„Ù„Ø¨Ù†Ø§Ø¡",
            "empty_docs": status["empty_docs"]
        }
    
    for i, (grade_key, subject_key, subject_folder) in enumerate(subjects_to_build):
        grade_name = GRADE_SUBJECTS[grade_key]['name']
        subject_name = GRADE_SUBJECTS[grade_key]['subjects'][subject_key]
        collection_name = f"{grade_key}_{subject_folder.replace(' ', '_').lower()}_coll"
        
        db_path = Path("chroma_dbs") / collection_name
        if db_path.exists() and not force_rebuild:
            try:
                data_files = list(db_path.glob("**/*"))
                if len([f for f in data_files if f.is_file()]) > 0:
                    results["skipped_databases"].append({
                        "name": collection_name,
                        "reason": "Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ ÙˆØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª"
                    })
                    continue
            except Exception as e:
                results["detailed_errors"].append(f"Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ {collection_name}: {e}")
        
        try:
            kb_manager = None
            retry_count = 3
            
            for attempt in range(retry_count):
                try:
                    kb_manager = KnowledgeBaseManager(
                        grade_folder_name=grade_key,
                        subject_folder_name=subject_folder,
                        project_id=project_id,
                        location=location,
                        force_recreate=force_rebuild
                    )
                    
                    if kb_manager.embedding_function and kb_manager.db:
                        break
                    else:
                        if attempt < retry_count - 1:
                            time.sleep(2)
                        else:
                            kb_manager = None
                except Exception as e:
                    if attempt < retry_count - 1:
                        time.sleep(2)
                    else:
                        results["detailed_errors"].append(f"ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯ÙŠØ± {collection_name}: {e}")
                        kb_manager = None
            
            if not kb_manager:
                results["failed_databases"].append({
                    "name": collection_name,
                    "reason": "ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯ÙŠØ± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"
                })
                continue
            
            build_success = False
            for attempt in range(2):
                try:
                    if kb_manager.build_knowledge_base():
                        build_success = True
                        break
                    else:
                        if attempt == 0:
                            time.sleep(1)
                except Exception as e:
                    results["detailed_errors"].append(f"Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ {collection_name} (Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}")
                    if attempt == 0:
                        time.sleep(1)
            
            if build_success:
                results["built_databases"].append(collection_name)
            else:
                results["failed_databases"].append({
                    "name": collection_name,
                    "reason": "ÙØ´Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¨Ù†Ø§Ø¡"
                })
                    
        except Exception as e:
            error_msg = f"Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø¨Ù†Ø§Ø¡ {collection_name}: {str(e)}"
            results["failed_databases"].append({
                "name": collection_name,
                "reason": error_msg
            })
            results["detailed_errors"].append(error_msg)
    
    return results

@st.cache_resource
def initialize_gemini_client(project_id: str, location: str):
    """ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Gemini Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    if not GEMINI_CLIENT_AVAILABLE:
        return None
        
    try:
        client = GeminiClientVertexAI(
            project_id=project_id,
            location=location,
            model_name="gemini-2.0-flash"
        )
        if client.model:
            return client
        return None
    except Exception as e:
        return None

@st.cache_resource
def initialize_knowledge_base(project_id: str, location: str, grade_key: str, subject_key: str):
    """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª"""
    if not KB_MANAGER_AVAILABLE:
        return None
        
    try:
        subject_folder = SUBJECT_FOLDERS.get(subject_key, subject_key)
        kb_manager = KnowledgeBaseManager(
            grade_folder_name=grade_key,
            subject_folder_name=subject_folder,
            project_id=project_id,
            location=location
        )
        return kb_manager
    except Exception as e:
        return None

@st.cache_resource
def initialize_prompt_engine():
    """ØªÙ‡ÙŠØ¦Ø© Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª"""
    if not PROMPT_ENGINE_AVAILABLE:
        return None
    return UnifiedPromptEngine()

def retrieve_context(kb_manager: Optional[any], query: str, k_results: int = 3) -> str:
    """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
    if not kb_manager or not hasattr(kb_manager, 'db') or not kb_manager.db:
        return ""
   
    try:
        docs = kb_manager.search_documents(query, k_results)
        if docs:
            context_parts = []
            for i, doc in enumerate(docs, 1):
                context_parts.append(f"[Ù…ØµØ¯Ø± {i}]: {doc.page_content}")
            return "\n\n".join(context_parts)
        return ""
    except Exception as e:
        return ""

def process_user_question_improved(question: str, gemini_client, kb_manager, prompt_engine, 
                                 grade_key: str, subject_key: str, chat_history: List[Dict] = None):
    """Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù†Ø© Ù…Ù† Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø¹ Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù… ÙˆØ¯Ø¹Ù… ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
    # ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù…
    question_type = classify_question_type(question, chat_history)
    
    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ­ÙŠØ§Øª
    if question_type['is_greeting']:
        return get_greeting_response(question, grade_key, subject_key)
    
    # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
    context = ""
    search_status = "not_searched"
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø±Ø§Ø¬Ø¹ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø¢Ø®Ø± Ù…ÙˆØ¶ÙˆØ¹ Ù„Ù„Ø¨Ø­Ø«
    search_query = question
    if question_type['has_references'] and chat_history:
        analyzer = ChatHistoryAnalyzer()
        last_topic = analyzer.extract_last_topic(chat_history)
        if last_topic:
            search_query = f"{last_topic} {question}"
    
    if should_search_curriculum(question, question_type):
        if kb_manager and hasattr(kb_manager, 'db') and kb_manager.db:
            try:
                context = retrieve_context(kb_manager, search_query)
                if context:
                    search_status = "found"
                else:
                    search_status = "not_found"
            except Exception as e:
                search_status = "error"
        else:
            search_status = "no_kb"
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ù…Ø¹ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù… ÙˆÙ…Ø±Ø§Ø¹Ø§Ø© ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    if prompt_engine:
        specialized_prompt = create_smart_prompt(
            question=question,
            question_type=question_type,
            app_subject_key=subject_key,
            grade_key=grade_key,
            retrieved_context_str=context if context else None,
            prompt_engine=prompt_engine,
            chat_history=chat_history
        )
    else:
        specialized_prompt = f"Ø£Ù†Øª Ù…Ø¹Ù„Ù… Ù„Ù„ØµÙ {grade_key} ÙÙŠ Ù…Ø§Ø¯Ø© {subject_key}. Ø§Ø´Ø±Ø­ Ù„Ù„Ø·ÙÙ„: {question}"
    
    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù€ Gemini
    if gemini_client:
        response = gemini_client.query_for_explanation_and_svg(specialized_prompt)
    else:
        response = {
            "text_explanation": "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ ØºÙŠØ± Ø¬Ø§Ù‡Ø² Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹.",
            "svg_code": None,
            "quality_scores": {},
            "quality_issues": ["Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ ØºÙŠØ± Ù…ØªØ§Ø­"]
        }
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù…: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ø³Ù… Ø¥Ø°Ø§ Ù„Ù… ÙŠÙ‚Ø±Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø£Ù†Ù‡ Ù…Ø·Ù„ÙˆØ¨
    if not question_type['needs_drawing']:
        response['svg_code'] = None
    
    return {
        'explanation': response.get("text_explanation", "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø¥Ù†ØªØ§Ø¬ Ø´Ø±Ø­ Ù…Ù†Ø§Ø³Ø¨."),
        'svg_code': response.get("svg_code"),
        'quality_scores': response.get("quality_scores", {}),
        'quality_issues': response.get("quality_issues", []),
        'search_status': search_status,
        'drawing_decision': question_type.get('smart_decision_reason', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯'),
        'drawing_confidence': question_type.get('drawing_confidence', 0),
        'question_analysis': {
            'is_high_priority_visual': question_type.get('is_high_priority_visual', False),
            'is_medium_priority_visual': question_type.get('is_medium_priority_visual', False),
            'is_math_question': question_type.get('is_math_question', False),
            'explicit_drawing': question_type.get('explicit_drawing_requested', False),
            'needs_drawing': question_type['needs_drawing']
        }
    }

def initialize_session_state():
    """ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©"""
    if 'messages' not in st.session_state:
        st.session_state.messages = []
   
    if 'selected_grade' not in st.session_state:
        st.session_state.selected_grade = 'grade_1'
   
    if 'selected_subject' not in st.session_state:
        st.session_state.selected_subject = 'arabic'
   
    if 'conversation_started' not in st.session_state:
        st.session_state.conversation_started = False
        
    if 'knowledge_bases_built' not in st.session_state:
        st.session_state.knowledge_bases_built = False

def display_sidebar():
    """Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø§Ù„Ù…Ø¨Ø³Ø·"""
    with st.sidebar:
        st.title("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¹Ù„Ù…")
       
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØµÙ
        grade_options = list(GRADE_SUBJECTS.keys())
        grade_display = [GRADE_SUBJECTS[g]['name'] for g in grade_options]
       
        current_grade_idx = grade_options.index(st.session_state.selected_grade) if st.session_state.selected_grade in grade_options else 0
       
        selected_grade_idx = st.selectbox(
            "ğŸ“š Ø§Ø®ØªØ± Ø§Ù„ØµÙ Ø§Ù„Ø¯Ø±Ø§Ø³ÙŠ:",
            range(len(grade_display)),
            format_func=lambda x: grade_display[x],
            index=current_grade_idx,
            key="grade_selector"
        )
        selected_grade = grade_options[selected_grade_idx]
       
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø§Ø¯Ø©
        subjects = GRADE_SUBJECTS[selected_grade]['subjects']
        subject_options = list(subjects.keys())
        subject_display = list(subjects.values())
       
        current_subject_idx = subject_options.index(st.session_state.selected_subject) if st.session_state.selected_subject in subject_options else 0
       
        selected_subject_idx = st.selectbox(
            "ğŸ“– Ø§Ø®ØªØ± Ø§Ù„Ù…Ø§Ø¯Ø©:",
            range(len(subject_display)),
            format_func=lambda x: subject_display[x],
            index=current_subject_idx,
            key="subject_selector"
        )
        selected_subject = subject_options[selected_subject_idx]
       
        # ØªØ­Ø¯ÙŠØ« session state ÙˆØ­Ø°Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ù†Ø¯ Ø§Ù„ØªØºÙŠÙŠØ±
        if (st.session_state.selected_grade != selected_grade or 
            st.session_state.selected_subject != selected_subject):
            # Ø­Ø°Ù Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¹Ù†Ø¯ ØªØºÙŠÙŠØ± Ø§Ù„ØµÙ Ø£Ùˆ Ø§Ù„Ù…Ø§Ø¯Ø©
            st.session_state.messages = []
            st.session_state.conversation_started = False
            st.session_state.selected_grade = selected_grade
            st.session_state.selected_subject = selected_subject
            st.rerun()
       
        return selected_grade, selected_subject

def add_message(role: str, content: str, **kwargs):
    """Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"""
    message = {
        "role": role,
        "content": content,
        "timestamp": datetime.now().strftime("%H:%M:%S"),
        "id": len(st.session_state.messages),
        **kwargs
    }
    st.session_state.messages.append(message)

def display_message(message: Dict, is_new: bool = False):
    """Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø¹Ø±Ø¶ SVG"""
   
    if message["role"] == "user":
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.write(f"**Ø£Ù†Øª:** {message['content']}")
            if 'timestamp' in message:
                st.caption(f"ğŸ•’ {message['timestamp']}")
   
    elif message["role"] == "assistant":
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            st.write("**Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ:**")
           
            # Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†ØµÙŠ
            if 'explanation' in message:
                st.write(message['explanation'])
           
            # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… SVG Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ù…Ø¹ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ø±Ø¶
            if 'svg_code' in message and message['svg_code']:
                st.subheader("ğŸ¨ Ø§Ù„Ø±Ø³Ù… Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ:")
               
                col1, col2 = st.columns([4, 1])
               
                with col1:
                    try:
                        # ØªØ­Ø³ÙŠÙ† Ø¹Ø±Ø¶ SVG Ù„ÙŠÙƒÙˆÙ† scalable ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø­Ø§ÙˆÙŠØ©
                        st.components.v1.html(
                            f"""
                            <div style="
                                display: flex; 
                                justify-content: center; 
                                align-items: center;
                                background-color: white; 
                                padding: 20px; 
                                border-radius: 10px;
                                border: 2px solid #e0e0e0;
                                width: 100%;
                                height: 400px;
                                overflow: hidden;
                            ">
                                <div style="
                                    width: 100%; 
                                    height: 100%; 
                                    display: flex; 
                                    justify-content: center; 
                                    align-items: center;
                                ">
                                    <svg style="
                                        max-width: 100%; 
                                        max-height: 100%; 
                                        width: auto; 
                                        height: auto;
                                    " viewBox="0 0 700 500" preserveAspectRatio="xMidYMid meet">
                                        {message['svg_code'].replace('<svg', '').replace('</svg>', '').replace('width="700"', '').replace('height="500"', '')}
                                    </svg>
                                </div>
                            </div>
                            """,
                            height=450
                        )
                    except Exception as e:
                        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù…: {e}")
               
                with col2:
                    st.write("ğŸ’¾ **ØªØ­Ù…ÙŠÙ„:**")
                   
                    st.download_button(
                        label="â¬‡ï¸ SVG",
                        data=message['svg_code'],
                        file_name=f"Ø±Ø³Ù…_ØªÙˆØ¶ÙŠØ­ÙŠ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.svg",
                        mime="image/svg+xml",
                        key=f"download_svg_{message.get('id', 'unknown')}"
                    )
                    
                    # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø±Ø§Ø± Ø§Ù„Ø±Ø³Ù… Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©
                    if 'drawing_decision' in message:
                        st.caption(f"ğŸ§  **Ù‚Ø±Ø§Ø± Ø§Ù„Ø±Ø³Ù…:** {message['drawing_decision']}")
                    
                    if 'drawing_confidence' in message:
                        confidence = message['drawing_confidence']
                        if confidence > 0:
                            st.caption(f"ğŸ“Š **Ø«Ù‚Ø© Ø§Ù„Ù‚Ø±Ø§Ø±:** {confidence}%")
           
            # Ø¹Ø±Ø¶ Ø§Ù„ÙˆÙ‚Øª
            if 'timestamp' in message:
                st.caption(f"ğŸ•’ {message['timestamp']}")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¹ Ø¯Ø¹Ù… Chat History Memory ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù…"""
   
    # ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
    initialize_session_state()
   
    st.title(APP_TITLE)
   
    # ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø¨ØµÙ…Øª
    project_id, location, credentials_path = load_environment_variables_silently()
    
    if not project_id:
        st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªØ¹ÙŠÙŠÙ† Ø¨ÙŠØ§Ù†Ø§Øª Google Cloud ÙÙŠ Streamlit Secrets")
        st.info("ğŸ’¡ ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚")
        st.stop()
    
    # ÙØ­Øµ ÙˆØ¨Ù†Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø± (Ø¨ØµÙ…Øª)
    if not st.session_state.knowledge_bases_built:
        kb_status = check_knowledge_base_detailed_status(project_id, location)
        
        if not kb_status["docs_exist"] or kb_status["total_found_docs"] == 0:
            st.session_state.knowledge_bases_built = True
        elif len(kb_status["missing_dbs"]) > 0:
            # Ø¨Ù†Ø§Ø¡ ØµØ§Ù…Øª Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ©
            build_result = build_knowledge_bases_with_error_handling(project_id, location)
            st.session_state.knowledge_bases_built = True
        else:
            st.session_state.knowledge_bases_built = True
   
    # Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    selected_grade, selected_subject = display_sidebar()
   
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø¨ØµÙ…Øª
    gemini_client = None
    if GEMINI_CLIENT_AVAILABLE:
        gemini_client = initialize_gemini_client(project_id, location)
    
    kb_manager = None
    if KB_MANAGER_AVAILABLE:
        kb_manager = initialize_knowledge_base(project_id, location, selected_grade, selected_subject)
    
    prompt_engine = initialize_prompt_engine()
   
    # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨ Ø¥Ø°Ø§ Ù„Ù… ØªØ¨Ø¯Ø£ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    if not st.session_state.conversation_started:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            st.write("**Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ:**")
            st.write(f"Ø£Ù‡Ù„Ø§Ù‹ ÙˆØ³Ù‡Ù„Ø§Ù‹! Ø£Ù†Ø§ Ù…Ø¹Ù„Ù…Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„ØµÙ {GRADE_SUBJECTS[selected_grade]['name']} ÙÙŠ Ù…Ø§Ø¯Ø© {GRADE_SUBJECTS[selected_grade]['subjects'][selected_subject]}.")
            if GEMINI_CLIENT_AVAILABLE and gemini_client:
                st.write("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø³Ø¤Ø§Ù„ ÙˆØ³Ø£Ø¬ÙŠØ¨Ùƒ Ø¨Ø´Ø±Ø­ Ù…Ø¨Ø³Ø· ÙˆØ±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©! ğŸ˜Š")
                st.write("ğŸ’¡ **Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø±Ø³Ù…:** Ø³Ø£Ù‚Ø±Ø± Ø¨Ù†ÙØ³ÙŠ Ù…ØªÙ‰ Ø£Ø­ØªØ§Ø¬ Ù„Ø±Ø³Ù… ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„ÙÙ‡Ù…!")
            else:
                st.write("ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„ØªÙƒ Ø§Ù„Ù†ØµÙŠØ©! ğŸ“š")
       
        st.session_state.conversation_started = True
   
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for message in st.session_state.messages:
        display_message(message)
   
    # Ù…Ø±Ø¨Ø¹ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
    if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§... ğŸ’­"):
        # Ø¥Ø¶Ø§ÙØ© Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        add_message("user", prompt)
        display_message(st.session_state.messages[-1])
       
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ¥Ù†ØªØ§Ø¬ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            st.write("**Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ:**")
           
            with st.spinner("ğŸ¤– Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ ÙŠÙÙƒØ± ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©..."):
                try:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ ØªÙ…Ø±ÙŠØ± ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                    response_data = process_user_question_improved(
                        prompt, gemini_client, kb_manager, prompt_engine,
                        selected_grade, selected_subject, st.session_state.messages[:-1]  # ØªÙ…Ø±ÙŠØ± ÙƒÙ„ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø­Ø§Ù„ÙŠ
                    )
                   
                    # Ø¹Ø±Ø¶ Ø§Ù„Ø´Ø±Ø­
                    st.write(response_data['explanation'])
                   
                    # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹ Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¬Ø¯ÙŠØ¯
                    if response_data['svg_code']:
                        st.subheader("ğŸ¨ Ø§Ù„Ø±Ø³Ù… Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ:")
                       
                        col1, col2 = st.columns([4, 1])
                       
                        with col1:
                            try:
                                # ØªØ­Ø³ÙŠÙ† Ø¹Ø±Ø¶ SVG Ù„ÙŠÙƒÙˆÙ† scalable ÙˆÙ…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø­Ø§ÙˆÙŠØ©
                                st.components.v1.html(
                                    f"""
                                    <div style="
                                        display: flex; 
                                        justify-content: center; 
                                        align-items: center;
                                        background-color: white; 
                                        padding: 20px; 
                                        border-radius: 10px;
                                        border: 2px solid #e0e0e0;
                                        width: 100%;
                                        height: 400px;
                                        overflow: hidden;
                                    ">
                                        <div style="
                                            width: 100%; 
                                            height: 100%; 
                                            display: flex; 
                                            justify-content: center; 
                                            align-items: center;
                                        ">
                                            <svg style="
                                                max-width: 100%; 
                                                max-height: 100%; 
                                                width: auto; 
                                                height: auto;
                                            " viewBox="0 0 700 500" preserveAspectRatio="xMidYMid meet">
                                                {response_data['svg_code'].replace('<svg', '').replace('</svg>', '').replace('width="700"', '').replace('height="500"', '')}
                                            </svg>
                                        </div>
                                    </div>
                                    """,
                                    height=450
                                )
                            except Exception as e:
                                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù…: {e}")
                       
                        with col2:
                            st.write("ğŸ’¾ **ØªØ­Ù…ÙŠÙ„:**")
                            st.download_button(
                                label="â¬‡ï¸ SVG",
                                data=response_data['svg_code'],
                                file_name=f"Ø±Ø³Ù…_ØªÙˆØ¶ÙŠØ­ÙŠ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.svg",
                                mime="image/svg+xml",
                                key=f"download_svg_new"
                            )
                            
                            # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø±Ø§Ø± Ø§Ù„Ø±Ø³Ù…
                            if response_data.get('drawing_decision'):
                                st.caption(f"ğŸ§  **Ù‚Ø±Ø§Ø± Ø§Ù„Ø±Ø³Ù…:** {response_data['drawing_decision']}")
                            
                            if response_data.get('drawing_confidence', 0) > 0:
                                confidence = response_data['drawing_confidence']
                                st.caption(f"ğŸ“Š **Ø«Ù‚Ø© Ø§Ù„Ù‚Ø±Ø§Ø±:** {confidence}%")
                    else:
                        # Ø¹Ø±Ø¶ Ø³Ø¨Ø¨ Ø¹Ø¯Ù… Ø§Ù„Ø±Ø³Ù… Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù‡Ù†Ø§Ùƒ Ø±Ø³Ù…
                        if response_data.get('drawing_decision'):
                            st.caption(f"ğŸ’­ **Ù„Ù…Ø§Ø°Ø§ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø³Ù…ØŸ** {response_data['drawing_decision']}")
                   
                    # Ø¥Ø¶Ø§ÙØ© Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                    add_message("assistant", "", **response_data)
                   
                except Exception as e:
                    error_msg = f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}"
                    st.error(error_msg)
                    add_message("assistant", error_msg)

if __name__ == "__main__":
    main()
